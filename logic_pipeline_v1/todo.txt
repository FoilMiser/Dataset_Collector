================================================================================
TODO — Logic Corpus Pipeline
================================================================================

Legend:
  [x] = Completed
  [~] = Partially addressed / MVP landed
  [ ] = Not yet implemented

================================================================================
VERSION HISTORY (logic adaptation)
================================================================================

v0.9 -> v1.0 Completed:
  [x] Adapt pipeline_driver + targets to logic inventory
  [x] License evidence + SPDX normalization carried over
  [x] Queue emission for GREEN/YELLOW/RED
  [x] Basic review helper + signoff schema (v0.2)
  [x] Logic-specific field_schemas + license_map skeletons

================================================================================
v1.0 -> v1.1 — WHAT NEEDS TO CHANGE / BE UPDATED
================================================================================

HIGH PRIORITY (Production readiness)
------------------------------------
1) Logic-focused extraction workers
   [ ] proof_repo_worker.py for Lean/Coq/Isabelle/Metamath repositories
   [ ] benchmark_worker.py for SMT-LIB/DIMACS parsing + metadata
   [ ] nl_logic_worker.py for NL reasoning datasets with split_group_id
   [ ] hook workers into yellow stage after review approval

2) Manual review UX
   [~] YELLOW review plan export (yellow_scrubber.py)
   [ ] Lightweight CLI to assign reviewers + track notes
   [ ] Optional FastAPI dashboard for approvals with provenance links

3) Testing + CI
   [ ] Unit tests for SPDX resolution + restriction scans
   [ ] Sample queue fixtures for logic targets
   [ ] Smoke test that classify -> download -> catalog runs on tiny fixtures

4) Documentation
   [ ] Worker how-to: adding new logic targets + extraction configs
   [ ] Review workflow guide (from queue to signoff)
   [ ] Troubleshooting FAQ for resolver failures (git/http/hf/zenodo)

MEDIUM PRIORITY (Quality + coverage)
------------------------------------
5) License handling and safety gates
   [ ] Implement record-level license checks for mixed benchmark pools
   [ ] Expand restriction phrase library for logic community licenses
   [ ] Add copyleft segregation enforcement in download_worker outputs

6) Data normalization
   [ ] Unicode/whitespace normalization options per worker
   [ ] Split-aware partitioning with split_group_id in catalogs
   [ ] Optional near-duplicate detection tuned for proof text

LOW PRIORITY (Ergonomics + future-proofing)
-------------------------------------------
7) Packaging + deployment
   [ ] Dockerfile for logic pipeline + example volume mounts
   [ ] Example orchestration (cron/Argo) for recurring runs
   [ ] Publish pinned requirements/lockfile

8) Observability
   [ ] Metrics on queue sizes, download throughput, and review turnaround
   [ ] Alerts for missing license evidence or stalled downloads

================================================================================
Notes for next iteration
================================================================================
- Keep synthetic/owned datasets clearly marked as permissive anchors.
- For community benchmarks, require per-contribution licensing and prefer sources with SPDX headers.
- Align catalogs with field_schemas versions once workers emit records.
