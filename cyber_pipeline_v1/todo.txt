================================================================================
TODO — Cybersecurity Corpus Pipeline
================================================================================

Legend:
  [x] = Completed
  [~] = Partially addressed / MVP landed
  [ ] = Not yet implemented

--------------------------------------------------------------------------------
Core gaps to reach v1.0
--------------------------------------------------------------------------------
1) Safety gates + filters
   [ ] Implement secret + PII scanning hooks referenced in targets.yaml
   [ ] Add dual-use/exploit content detection prior to emitting text
   [~] Harden denylist patterns with automated domain/provider extraction

2) Structured source normalization
   [~] Wire stix_worker.py, nvd_worker.py, and advisory_worker.py into yellow stage
   [ ] Schema validation against field_schemas.yaml for each normalized record
   [ ] Example configs + sample fixtures for the three normalizers

3) Governance + auditability
   [ ] CI checks for license evidence diffs and restriction phrase hits
   [ ] Smoke tests covering classify → download → catalog in dry-run mode
   [ ] Review queue UX: CSV/JSON exports already present; need CLI filters by bucket/tag

4) Packaging + usability
   [ ] Container image (requests + basic scanners baked in)
   [ ] makefile or invoke tasks for common workflows
   [ ] Metrics/logging sinks for long-running downloads

--------------------------------------------------------------------------------
Future improvements (post-v1.0)
--------------------------------------------------------------------------------
5) Coverage expansions
   [ ] Additional ICS advisories (CISA KEV mirror, vendor PSIRTs)
   [ ] Sigma/YARA corpus ingestion with safe rule linting
   [ ] Threat intel reports with scrubbing rules for sensitive IoCs

6) Ergonomics + monitoring
   [ ] Optional dashboards for queue status and throughput
   [ ] Slack/email notifications on stalled runs or license changes
   [ ] Token accounting reports by data type (advisory vs incident writeups)

7) Quality + deduplication
   [ ] Broader near-duplicate detection tuned for short advisories
   [ ] Language detection and minimal-quality thresholds for web-sourced text
   [ ] Per-target attribution bundles with machine-readable license metadata
