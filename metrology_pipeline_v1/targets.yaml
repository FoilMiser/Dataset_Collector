# targets.yaml
# v1.0 — metrology + technical reports
#
# Purpose:
#   Curate legally-cleared, engineering-rigorous text with strong metrology / standards
#   flavor (NIST/NASA/USGS/NOAA style) for LLM training.
#
# Notes:
#   - Schema-compatible with chem_pipeline_v1 (pipeline_driver.py v1.0).
#   - Adds metrology-specific resolvers (API harvesters) and technical-report chunking defaults.
#   - High-value harvesters that require new workers are present but disabled by default.
#
# Source documents for adaptation:
#   - METROLOGY_PIPELINE_ADAPTATION.md (see repo root)
#   - targets_metrology.yaml seed (repo root)

schema_version: "0.8"
updated_utc: "2025-12-20"

companion_files:
  license_map: "./license_map.yaml"
  field_schemas: "./field_schemas.yaml"
  denylist: "./denylist.yaml"

globals:
  storage_root: "/data/metrology"
  staging_root: "/data/metrology/_staging"
  manifests_root: "/data/metrology/_manifests"
  queues_root: "/data/metrology/_queues"
  catalogs_root: "/data/metrology/_catalogs"
  logs_root: "/data/metrology/_logs"

  pools:
    permissive: "/data/metrology/pools/permissive"
    copyleft: "/data/metrology/pools/copyleft"
    quarantine: "/data/metrology/pools/quarantine"

  # Require signoff for all YELLOW items (manual review). Keep false for early iteration.
  require_yellow_signoff: false

  # Default gates applied to every target unless overridden.
  default_gates:
    - "snapshot_terms"
    - "resolve_license_spdx"
    - "restriction_phrase_scan"
    - "emit_training_manifest"
    - "emit_attribution_bundle"

  # Near-duplicate detection (recommended once you start harvesting at scale).
  near_duplicate_detection:
    enabled: false
    method: "minhash_lsh"    # minhash_lsh | exact_hash
    num_perm: 128
    threshold: 0.90

  # Text chunking defaults for technical reports (PDF/HTML)
  text_processing_defaults:
    max_chunk_chars: 7000
    min_chunk_chars: 600
    drop_tables: false                 # metrology often encodes definitions in tables
    drop_references_section: false     # references are useful for "how reports cite"
    keep_citations_inline: true
    include_section_headers: true
    include_figure_captions: true
    include_table_captions: true

  download_defaults:
    retry_max: 3
    retry_backoff_base: 2.0
    retry_backoff_max: 60
    timeout_connect: 30
    timeout_read: 300
    verify_checksums: true
    enable_resume: true
    max_concurrent_workers: 4
    user_agent: "metrology-corpus-pipeline/1.0"

queues:
  - id: "green_download"
    path: "/data/metrology/_queues/green_download.jsonl"
  - id: "yellow_pipeline"
    path: "/data/metrology/_queues/yellow_pipeline.jsonl"
  - id: "red_rejected"
    path: "/data/metrology/_queues/red_rejected.jsonl"

# Documentation-only catalog of planned gates.
# (pipeline_driver.py does not currently enforce this list; it’s a shared vocabulary.)
gates_catalog:
  snapshot_terms:
    desc: "Snapshot and hash terms-of-use and license pages."
  resolve_license_spdx:
    desc: "Normalize license into SPDX-like ID using license_map.yaml."
  restriction_phrase_scan:
    desc: "Scan for restrictive phrases (e.g., 'no redistribution', 'export controlled')."
  export_control_scan:
    desc: "Scan for export-control / ITAR / EAR distribution statements (TODO: implement)."
  distribution_statement_scan:
    desc: "Scan DoD/NASA distribution statements (TODO: implement)."
  record_level_filter:
    desc: "Per-record allowlist/denylist when dataset contains mixed rights."
  extract_text_chunks:
    desc: "Extract text from PDFs/HTML and emit chunked JSONL with structure."
  emit_training_manifest:
    desc: "Emit training manifest with IDs, provenance, and licensing evidence."
  emit_attribution_bundle:
    desc: "Emit attribution bundle (sources, notices, required credit)."
  manual_legal_review:
    desc: "Human signoff step in _manifests/<target_id>/review_signoff.json."
  near_duplicate_detection:
    desc: "MinHash/LSH or exact-hash dedup (optional)."

# Resolvers describe "how to interpret" download blocks.
# download_worker.py currently implements: http, ftp, git, zenodo, dataverse, huggingface_datasets
# TODO: implement new resolvers (api, ntrs_openapi, usgs_pubs_warehouse, noaa_ir_json, faa_ac_crawl).
resolvers:
  http:
    mode: "urls"
    note: "Direct URLs to files (PDF/zip/txt)."
  ftp:
    mode: "base_url + globs"
    note: "List + filter by glob; store directory listing snapshot."
  git:
    mode: "repo"
    note: "Capture commit hash; store LICENSE + README as evidence."
  zenodo:
    mode: "record_id"
    note: "Download Zenodo record; store record JSON as evidence."
  dataverse:
    mode: "persistent_id"
    note: "Download Dataverse dataset zip via persistentId."
  huggingface_datasets:
    mode: "dataset_id"
    note: "Use datasets.load_dataset; store dataset card + license field."
  api:
    mode: "base_url"
    note: "TODO: implement API harvester with paging + evidence snapshots."
  ntrs_openapi:
    mode: "base_url"
    note: "TODO: implement NASA NTRS OpenAPI harvester -> citations + fulltext PDFs."
  usgs_pubs_warehouse:
    mode: "base_url"
    note: "TODO: implement USGS Pubs Warehouse REST harvester -> records + fulltext."
  noaa_ir_json:
    mode: "base_url"
    note: "TODO: implement NOAA IR JSON API harvester -> records + PDFs."
  faa_ac_crawl:
    mode: "index_url"
    note: "TODO: crawl FAA Advisory Circular listing -> PDF URLs + metadata."

targets:

  # ------------------------------------------------------------
  # A) Small, high-signal seed set (GREEN) — good for early smoke tests
  # ------------------------------------------------------------

  - id: "bipm_si_brochure_latest"
    name: "BIPM SI Brochure (International System of Units) — CC BY 4.0"
    enabled: true
    priority: 1
    publisher: "BIPM"
    license_profile: "permissive"
    license_evidence:
      spdx_hint: "CC-BY-4.0"
      url: "https://www.bipm.org/en/publications/si-brochure"
    data_type: ["metrology", "units", "standards_guidance", "technical_report"]
    download:
      strategy: "http"
      urls:
        - "https://www.bipm.org/documents/20126/41483022/SI-Brochure-9-EN.pdf"
    output:
      pool: "permissive"
      formats: ["pdf"]
    gates_override:
      add: ["extract_text_chunks", "emit_training_manifest", "emit_attribution_bundle"]

  - id: "nist_sp_330_si_brochure_us"
    name: "NIST SP 330-2019: The International System of Units (SI), 2019 Edition (US adaptation)"
    enabled: true
    priority: 2
    publisher: "NIST"
    license_profile: "permissive"
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://www.nist.gov/open/license"
    data_type: ["metrology", "units", "standards_guidance", "technical_report"]
    download:
      strategy: "http"
      urls:
        - "https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.330-2019.pdf"
    output:
      pool: "permissive"
      formats: ["pdf"]
    gates_override:
      add: ["extract_text_chunks", "emit_training_manifest", "emit_attribution_bundle"]

  - id: "nist_rdaf_sp_1500_18r2_html"
    name: "NIST Research Data Framework (SP 1500-18r2) — HTML landing (for 'how NIST writes guidance')"
    enabled: true
    priority: 3
    publisher: "NIST"
    license_profile: "permissive"
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://www.nist.gov/open/license"
    data_type: ["policy_guidance", "research_data", "technical_report", "nist_style"]
    download:
      strategy: "http"
      urls:
        - "https://nvlpubs.nist.gov/nistpubs/SpecialPublications/1500-18/NIST.SP.1500-18r2.html"
    output:
      pool: "permissive"
      formats: ["html"]
    gates_override:
      add: ["extract_text_chunks", "emit_training_manifest", "emit_attribution_bundle"]

  # ------------------------------------------------------------
  # B) NIST technical report corpus — start with metadata (GREEN), then harvest fulltext (YELLOW->GREEN)
  # ------------------------------------------------------------

  - id: "nist_technical_series_publication_metadata"
    name: "NIST Technical Series Publication Metadata (Crossref exports) — monthly updated"
    enabled: true
    priority: 5
    publisher: "NIST"
    license_profile: "permissive"
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://catalog.data.gov/dataset/nist-technical-series-publication-metadata"
    data_type: ["metadata", "catalog", "nist_tech_series", "dois"]
    download:
      strategy: "http"
      urls:
        - "https://data.nist.gov/od/ds/mds2-2192/DOIMETADATA_MASTER.txt"
        - "https://data.nist.gov/od/ds/mds2-2192/allrecords.xml"
        - "https://data.nist.gov/od/ds/mds2-2192/readme.txt"
    output:
      pool: "permissive"
      formats: ["txt", "xml"]
    gates_override:
      add: ["emit_training_manifest", "emit_attribution_bundle"]

  - id: "nist_nvlpubs_fulltext_harvest"
    name: "NIST NVL PubS full-text harvest (SP/TN/NISTIR/HB/etc) — TODO implement"
    enabled: false
    priority: 6
    publisher: "NIST"
    license_profile: "record_level"
    review_required: true
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://www.nist.gov/open/license"
    data_type: ["technical_report", "nist_style", "metrology", "measurement_uncertainty", "calibration"]
    download:
      strategy: "api"           # TODO: implement
      base_url: "https://nvlpubs.nist.gov/"
      note: "Harvest using metadata (DOI/report IDs) -> download PDFs/HTML. Respect robots/terms and store evidence."
    gates_override:
      add: ["manual_legal_review", "record_level_filter", "extract_text_chunks", "near_duplicate_detection"]
    output:
      pool: "quarantine"
      formats: ["jsonl.gz", "parquet"]

  # ------------------------------------------------------------
  # C) NASA NTRS (NTRS OpenAPI) — huge value, but mixed rights/distribution ⇒ YELLOW by default
  # ------------------------------------------------------------

  - id: "nasa_ntrs_openapi_public_harvest"
    name: "NASA STI Repository (NTRS) OpenAPI — PUBLIC + unclassified harvest (TODO implement)"
    enabled: false
    priority: 8
    publisher: "NASA"
    license_profile: "record_level"
    review_required: true
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://sti.nasa.gov/harvesting-data-from-ntrs/"
    data_type: ["technical_report", "nasa_style", "engineering", "test_reports", "handbooks", "ntrs"]
    download:
      strategy: "ntrs_openapi"   # TODO: implement
      base_url: "https://ntrs.nasa.gov/api"
      query_defaults:
        distribution: "PUBLIC"
        disseminated: "DOCUMENT_AND_METADATA"
    gates_override:
      add: ["manual_legal_review", "distribution_statement_scan", "record_level_filter", "extract_text_chunks", "near_duplicate_detection"]
    output:
      pool: "quarantine"
    formats: ["jsonl.gz", "parquet"]

  # ------------------------------------------------------------
  # D) USGS publications — authoritative technical writing, methods, calibration, uncertainty
  # ------------------------------------------------------------

  - id: "usgs_pubs_warehouse_harvest"
    name: "USGS Publications Warehouse (REST web services) — TODO implement"
    enabled: false
    priority: 10
    publisher: "USGS"
    license_profile: "record_level"
    review_required: true
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://pubs.usgs.gov/documentation/web_service_documentation"
    data_type: ["technical_report", "methods", "measurement", "instrumentation", "calibration", "uncertainty"]
    download:
      strategy: "usgs_pubs_warehouse"  # TODO: implement
      base_url: "https://pubs.usgs.gov/"
      query_defaults:
        format: "json"
    gates_override:
      add: ["manual_legal_review", "record_level_filter", "extract_text_chunks", "near_duplicate_detection"]
    output:
      pool: "quarantine"
      formats: ["jsonl.gz", "parquet"]

  # ------------------------------------------------------------
  # E) NOAA technical memoranda — good “engineering memo” genre; harvesting via NOAA IR JSON API
  # ------------------------------------------------------------

  - id: "noaa_ir_json_api_harvest"
    name: "NOAA Institutional Repository (NOAA IR) JSON API — TODO implement"
    enabled: false
    priority: 12
    publisher: "NOAA"
    license_profile: "record_level"
    review_required: true
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://github.com/NOAA-Central-Library-NCL/NOAA_IR"
    data_type: ["technical_report", "noaa_style", "methods", "instrumentation"]
    download:
      strategy: "noaa_ir_json"     # TODO: implement
      base_url: "https://repository.library.noaa.gov/"
    gates_override:
      add: ["manual_legal_review", "record_level_filter", "extract_text_chunks", "near_duplicate_detection"]
    output:
      pool: "quarantine"
      formats: ["jsonl.gz", "parquet"]

  - id: "noaa_seed_tech_memos"
    name: "NOAA Technical Memorandum seed PDF (small sample for smoke test)"
    enabled: false
    priority: 13
    publisher: "NOAA"
    license_profile: "permissive"
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://library.noaa.gov/author-publishing/NOAA-Publications"
    data_type: ["technical_report", "noaa_style", "methods"]
    download:
      strategy: "http"
      urls:
        - "https://www.arl.noaa.gov/documents/reports/arl-230.pdf"
    output:
      pool: "permissive"
      formats: ["pdf"]
    gates_override:
      add: ["extract_text_chunks", "emit_training_manifest", "emit_attribution_bundle"]

  # ------------------------------------------------------------
  # F) Safety / standards-adjacent technical docs that often contain metrology (optional)
  # ------------------------------------------------------------

  - id: "ntsb_aviation_accident_data_census"
    name: "NTSB Aviation Accident Data Census (ZIP) + coding manuals (data engineering + rigor)"
    enabled: false
    priority: 20
    publisher: "NTSB"
    license_profile: "permissive"
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://data.ntsb.gov/avdata"
    data_type: ["datasets", "coding_manuals", "data_definitions", "safety"]
    download:
      strategy: "http"
      urls:
        - "https://data.ntsb.gov/avdata/avall.zip"
        - "https://data.ntsb.gov/avdata/PRE1982.zip"
        - "https://data.ntsb.gov/avdata/Pre2008.zip"
        - "https://data.ntsb.gov/avdata/eadmspub.pdf"
        - "https://data.ntsb.gov/avdata/MDB_Release_Notes.pdf"
    output:
      pool: "permissive"
      formats: ["zip", "pdf"]
    gates_override:
      add: ["extract_text_chunks", "emit_training_manifest", "emit_attribution_bundle"]

  - id: "faa_advisory_circulars_harvest"
    name: "FAA Advisory Circulars (AC) — TODO implement crawler (many PDFs)"
    enabled: false
    priority: 22
    publisher: "FAA"
    license_profile: "record_level"
    review_required: true
    license_evidence:
      spdx_hint: "US-PUBLIC-DOMAIN"
      url: "https://www.faa.gov/regulations_policies/advisory_circulars/"
    data_type: ["technical_guidance", "procedures", "safety", "standards"]
    download:
      strategy: "faa_ac_crawl"   # TODO: implement
      index_url: "https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.list"
    gates_override:
      add: ["manual_legal_review", "record_level_filter", "extract_text_chunks", "near_duplicate_detection"]
    output:
      pool: "quarantine"
      formats: ["jsonl.gz", "parquet"]

  # ------------------------------------------------------------
  # G) Common Pile — optional “background” data; keep disabled unless you’re filtering hard
  # ------------------------------------------------------------

  - id: "common_pile_arxiv_abstracts"
    name: "Common Pile v0.1 — arXiv abstracts (background scientific writing)"
    enabled: false
    priority: 50
    publisher: "Common Pile"
    license_profile: "record_level"
    review_required: true
    license_evidence:
      spdx_hint: "Derived"
      url: "https://huggingface.co/datasets/common-pile/arxiv_abstracts"
    data_type: ["commonpile", "scientific_writing", "background"]
    download:
      strategy: "huggingface_datasets"
      dataset_id: "common-pile/arxiv_abstracts"
      splits: ["train"]
    output:
      pool: "quarantine"
      formats: ["hf_dataset"]
    gates_override:
      add: ["manual_legal_review", "record_level_filter", "near_duplicate_detection"]

  - id: "common_pile_doab"
    name: "Common Pile v0.1 — DOAB (open access books; useful but broad)"
    enabled: false
    priority: 51
    publisher: "Common Pile"
    license_profile: "record_level"
    review_required: true
    license_evidence:
      spdx_hint: "Derived"
      url: "https://huggingface.co/datasets/common-pile/doab"
    data_type: ["commonpile", "books", "background"]
    download:
      strategy: "huggingface_datasets"
      dataset_id: "common-pile/doab"
      splits: ["train"]
    output:
      pool: "quarantine"
      formats: ["hf_dataset"]
    gates_override:
      add: ["manual_legal_review", "record_level_filter", "near_duplicate_detection"]

  # ------------------------------------------------------------
  # H) RED list (explicitly avoid) — keep as documentation only
  # ------------------------------------------------------------

  - id: "iso_standards_paywalled"
    name: "ISO/IEC standards text (paywalled / restrictive) — DO NOT INGEST"
    enabled: false
    priority: 99
    publisher: "ISO/IEC"
    license_profile: "deny"
    license_evidence:
      spdx_hint: "All-Rights-Reserved"
      url: ""
    data_type: ["standards", "restricted"]
    download:
      strategy: "none"

  - id: "ieee_standards_paywalled"
    name: "IEEE standards text (paywalled / restrictive) — DO NOT INGEST"
    enabled: false
    priority: 99
    publisher: "IEEE"
    license_profile: "deny"
    license_evidence:
      spdx_hint: "All-Rights-Reserved"
      url: ""
    data_type: ["standards", "restricted"]
    download:
      strategy: "none"
